{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prematurity classification on the dHCP database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, permutation_test_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import re\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedGroupKFold, KFold\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/neurospin/dico/data/deep_folding/current/models/Champollion_V1_after_ablation\"\n",
    "labels_path = \"/neurospin/dico/data/deep_folding/current/datasets/dHCP_374_subjects/participants.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_ids(s):\n",
    "\n",
    "    s = s.astype(str).str.strip().str.lower()\n",
    "\n",
    "    s = s.str.replace(r'^(sub-)', '', regex=True)\n",
    "    return s\n",
    "\n",
    "\n",
    "def load_cognition_df():\n",
    "    path = \"/neurospin/dico/rmenasria/Runs/03_main/Input/dHCP/cognitive_scores_with_age_dHCP.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Participant ID\" not in df.columns:\n",
    "        raise ValueError(\"Colonne 'Participant ID' absente du CSV cognition.\")\n",
    "    if \"Child's Sex\" not in df.columns:\n",
    "        raise ValueError(\"Colonne \\\"Child's Sex\\\" absente du CSV cognition.\")\n",
    "    df[\"pid_norm\"] = _normalize_ids(df[\"Participant ID\"])\n",
    "    df = df.drop_duplicates(subset=[\"pid_norm\"], keep=\"first\")\n",
    "    return df[[\"pid_norm\", \"Child's Sex\"]]\n",
    "\n",
    "\n",
    "def load_participants_labels(labels_path):\n",
    "    df = pd.read_csv(labels_path)\n",
    "    if \"Subject\" not in df.columns or \"birth_age\" not in df.columns:\n",
    "        raise ValueError(\"Le CSV participants doit contenir 'Subject' et 'birth_age'.\")\n",
    "    df[\"pid_norm\"] = _normalize_ids(df[\"Subject\"])\n",
    "    # fabriquer prem_class depuis birth_age\n",
    "    ba = df[\"birth_age\"].astype(float)\n",
    "    prem_class = np.where(ba < 28, \"<28\",\n",
    "                   np.where(ba < 32, \"28-32\",\n",
    "                   np.where(ba < 37, \"32-37\", \">=37\")))\n",
    "    df[\"prem_class\"] = prem_class\n",
    "    df = df.drop_duplicates(subset=[\"pid_norm\"], keep=\"first\")\n",
    "    return df[[\"pid_norm\", \"prem_class\"]]\n",
    "\n",
    "\n",
    "def load_embeddings_dHCP(region) :\n",
    "    region_path = os.path.join(base_path, region)\n",
    "    subdirs = [d for d in os.listdir(region_path) if os.path.isdir(os.path.join(region_path, d))]\n",
    "    if len(subdirs) != 1:\n",
    "        raise RuntimeError(f\"{region_path}: attendu 1 sous-dossier de modèle, trouvé {len(subdirs)}.\")\n",
    "    model_folder = subdirs[0]\n",
    "    embedding_path = os.path.join(region_path, model_folder, \"dHCP_random_embeddings\", \"full_embeddings.csv\")\n",
    "    emb = pd.read_csv(embedding_path, index_col=0)\n",
    "    emb.index = _normalize_ids(emb.index)\n",
    "    emb.index.name = \"pid_norm\"\n",
    "    emb = emb[~emb.index.duplicated(keep=\"first\")]\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualizerSexeFromX(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Suppose que la dernière colonne de X est le sexe binaire {0,1}.\n",
    "    - fit : pour chaque feature j, ajuste x_j ~ a_j + b_j*sexe\n",
    "    - transform : retourne les résidus (x_j - prédiction), en enlevant la colonne sexe.\n",
    "    \"\"\"\n",
    "    def __init__(self, sex_col_index: int = -1):\n",
    "        self.sex_col_index = sex_col_index\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        X = np.asarray(X, dtype=float)\n",
    "        sex = X[:, self.sex_col_index]\n",
    "        feats = np.delete(X, self.sex_col_index, axis=1)\n",
    "\n",
    "        # Vérif binaire\n",
    "        uniq = np.unique(sex[~np.isnan(sex)])\n",
    "        if not np.all(np.isin(uniq, [0.0, 1.0])):\n",
    "            warnings.warn(\"Colonne sexe pas strictement binaire {0,1}.\")\n",
    "\n",
    "        # Formules fermées de la régression OLS par dimension\n",
    "        s_mean, s_var = np.nanmean(sex), np.nanvar(sex)\n",
    "        X_mean = np.nanmean(feats, axis=0)\n",
    "\n",
    "        if s_var <= 0:\n",
    "            beta = np.zeros(feats.shape[1])\n",
    "            alpha = X_mean.copy()\n",
    "        else:\n",
    "            cov = np.nanmean((feats - X_mean) * (sex[:, None] - s_mean), axis=0)\n",
    "            beta = cov / s_var\n",
    "            alpha = X_mean - beta * s_mean\n",
    "\n",
    "        self.alpha_ = alpha\n",
    "        self.beta_ = beta\n",
    "        self.n_features_ = feats.shape[1]\n",
    "        self.sex_col_index_ = self.sex_col_index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, [\"alpha_\", \"beta_\"])\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        sex = X[:, self.sex_col_index_]\n",
    "        feats = np.delete(X, self.sex_col_index_, axis=1)\n",
    "        pred = self.alpha_[None, :] + sex[:, None] * self.beta_[None, :]\n",
    "\n",
    "        return feats - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PreparedData:\n",
    "    X: np.ndarray            # embeddings + sexe concaténés (dernière colonne = sexe)\n",
    "    y: np.ndarray            # binaire: 1 = prem_target, 0 = autre (dans prem_class filtrées)\n",
    "    groups: np.ndarray\n",
    "    idx_keep: np.ndarray\n",
    "    embedding_cols: List[str]  # noms des features + [\"_sex_num\"] à la fin\n",
    "    n_splits: int\n",
    "\n",
    "def prepare_dhcp_for_prematurity(\n",
    "    region: str,\n",
    "    labels_path: str,\n",
    "    prem_class: List[str],       # p.ex. [\"28-32\", \">=37\"]\n",
    "    prem_target: str,            # p.ex. \"28-32\"\n",
    "    sex_col: str = \"Child's Sex\",\n",
    "    group_col: Optional[str] = None,\n",
    "    min_splits: int = 5\n",
    ") -> PreparedData:\n",
    "    emb_df = load_embeddings_dHCP(region)\n",
    "    part_df = load_participants_labels(labels_path)      # prem_class depuis birth_age\n",
    "    sex_df = load_cognition_df()                         # sexe depuis cognition\n",
    "\n",
    "    # merge Embeddings × Participants (labels)\n",
    "    merged = part_df.merge(emb_df, left_on=\"pid_norm\", right_index=True, how=\"inner\")\n",
    "\n",
    "    # merge sexe\n",
    "    merged = merged.merge(sex_df, on=\"pid_norm\", how=\"left\")\n",
    "    if merged[\"Child's Sex\"].isna().any():\n",
    "        n_missing = merged[\"Child's Sex\"].isna().sum()\n",
    "        warnings.warn(f\"{region}: {n_missing} sujets sans sexe dans le CSV cognition — ils seront droppés.\")\n",
    "\n",
    "    # filtre classes gardées\n",
    "    before = merged.shape[0]\n",
    "    merged = merged[merged[\"prem_class\"].isin(prem_class)].copy()\n",
    "    print(f\"[{region}] filtre prem_class {prem_class}: {before} -> {merged.shape[0]}\")\n",
    "\n",
    "    # encode sexe\n",
    "    sex_map = {\"male\": 0, \"female\": 1, \"m\": 0, \"f\": 1}\n",
    "    merged[\"_sex_num\"] = _normalize_ids(merged[sex_col]).map(sex_map).astype(float)\n",
    "\n",
    "    # features embedding\n",
    "    embedding_cols = [c for c in merged.columns if re.match(r\"^dim\", c)]\n",
    "    if not embedding_cols:\n",
    "        raise ValueError(\"Aucune colonne d'embeddings 'dim...' trouvée après merge.\")\n",
    "    X_emb = merged[embedding_cols].values.astype(float)\n",
    "\n",
    "    # target binaire\n",
    "    y = (merged[\"prem_class\"] == prem_target).astype(int).values\n",
    "    sex_vec = merged[\"_sex_num\"].values.astype(float)\n",
    "\n",
    "    # groups (facultatif)\n",
    "    if group_col is None:\n",
    "        groups = merged[\"pid_norm\"].astype(str).values\n",
    "    else:\n",
    "        if group_col not in merged.columns:\n",
    "            raise ValueError(f\"Colonne de groupe '{group_col}' absente du merged.\")\n",
    "        groups = merged[group_col].astype(str).values\n",
    "\n",
    "    # clean\n",
    "    keep = (~pd.isna(y)) & (~np.isnan(sex_vec))\n",
    "    X_emb, y, sex_vec, groups = X_emb[keep], y[keep], sex_vec[keep], groups[keep]\n",
    "\n",
    "    # concat sexe en dernière colonne\n",
    "    X_aug = np.column_stack([X_emb, sex_vec])\n",
    "\n",
    "    # n_splits selon minorité\n",
    "    counts = pd.Series(y).value_counts()\n",
    "    max_splits = int(counts.min()) if not counts.empty else 2\n",
    "    n_splits = max(2, min(min_splits, max_splits))\n",
    "\n",
    "    return PreparedData(\n",
    "        X=X_aug, y=y, groups=groups, idx_keep=keep,\n",
    "        embedding_cols=embedding_cols + [\"_sex_num\"], n_splits=n_splits\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_prematurity_with_perm(\n",
    "    data: PreparedData,\n",
    "    Cs: Tuple[float, ...] = (0.01, 0.1, 1, 10),\n",
    "    n_splits: Optional[int] = None,\n",
    "    random_state: int = 42,\n",
    "    n_jobs: int = -1,\n",
    "    n_permutations: int = 200\n",
    "):\n",
    "    if n_splits is None:\n",
    "        n_splits = data.n_splits\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"resid\", ResidualizerSexeFromX()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\"))\n",
    "    ])\n",
    "\n",
    "    # sélection de C par CV\n",
    "    results = []\n",
    "    for C in Cs:\n",
    "        pipe.set_params(clf__C=C)\n",
    "        aucs = cross_val_score(\n",
    "            pipe, data.X, data.y,\n",
    "            cv=skf, scoring=\"roc_auc\", n_jobs=n_jobs\n",
    "        )\n",
    "        results.append((C, aucs))\n",
    "    best_idx = int(np.argmax([np.mean(aucs) for _, aucs in results]))\n",
    "    best_C, best_aucs = results[best_idx]\n",
    "\n",
    "    # permutations uniquement sur best_C\n",
    "    pipe.set_params(clf__C=best_C)\n",
    "    perm_score, perm_scores, pval = permutation_test_score(\n",
    "        pipe, data.X, data.y,\n",
    "        scoring=\"roc_auc\", cv=skf,\n",
    "        n_permutations=n_permutations, n_jobs=n_jobs,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    ci95 = float(np.percentile(perm_scores, 95))\n",
    "\n",
    "    # fit final pour coefficients (dans l'espace original, après résidualisation, avant scaling)\n",
    "    pipe.fit(data.X, data.y)\n",
    "    scaler = pipe.named_steps[\"scaler\"]\n",
    "    clf = pipe.named_steps[\"clf\"]\n",
    "    coefs_scaled = clf.coef_.ravel()\n",
    "    coefs_unscaled = coefs_scaled / scaler.scale_\n",
    "    intercept_unscaled = float(clf.intercept_ - np.sum(coefs_scaled * scaler.mean_ / scaler.scale_))\n",
    "    coef_dict = {name: float(w) for name, w in zip(data.embedding_cols, coefs_unscaled)}\n",
    "\n",
    "    return {\n",
    "        \"best_C\": float(best_C),\n",
    "        \"AUC_mean\": float(np.mean(best_aucs)),\n",
    "        \"AUC_std\": float(np.std(best_aucs)),\n",
    "        \"perm_score\": float(perm_score),\n",
    "        \"perm_pval\": float(pval),\n",
    "        \"perm_ci95\": ci95,\n",
    "        \"all_results\": {float(C): aucs.tolist() for C, aucs in results},\n",
    "        \"coef_unscaled\": coef_dict,\n",
    "        \"intercept_unscaled\": intercept_unscaled\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prem_direction(data):\n",
    "    # direction prematurité\n",
    "    pipe = Pipeline([\n",
    "        (\"resid\", ResidualizerSexeFromX()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(class_weight=\"balanced\", C=10, solver=\"liblinear\"))\n",
    "    ])\n",
    "    pipe.fit(data.X, data.y)\n",
    "    pipe.predict(data.X)\n",
    "\n",
    "    # get the subject names and their corresponding predicted scores\n",
    "\n",
    "    # Projection brute des individus\n",
    "    projection = pipe.predict_proba(data.X)[:, 1]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"subject\": data.groups,   # identifiant sujet\n",
    "        \"y_true\": data.y,         # score cognitif\n",
    "        \"projection\": projection  # projection sur la direction\n",
    "    })\n",
    "\n",
    "    # trier du plus grand au plus petit\n",
    "    df = df.sort_values(by=\"projection\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FCMpost-SpC_right] filtre prem_class ['28-32', '>=37']: 374 -> 312\n"
     ]
    }
   ],
   "source": [
    "data = prepare_dhcp_for_prematurity(\n",
    "    \"FCMpost-SpC_right\",\n",
    "    labels_path=labels_path,\n",
    "    prem_class=['28-32','>=37'],\n",
    "    prem_target='28-32',\n",
    ")\n",
    "\n",
    "df_proj = prem_direction(data)\n",
    "\n",
    "df_proj.to_csv(\n",
    "    \"/neurospin/dico/rmenasria/Runs/03_main/Output/final_direction/dHCP/projection_FCMpost-SpC_right_28_32.csv\",\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 subjects with highest projection scores:\n",
      "0     CC00657XX14\n",
      "1     CC00600XX06\n",
      "2     CC00583XX15\n",
      "3     CC00412XX08\n",
      "4     CC00245BN15\n",
      "5     CC00202XX04\n",
      "6     CC00152AN04\n",
      "7     CC00672AN13\n",
      "8     CC00102XX03\n",
      "9     CC00731XX14\n",
      "10    CC00162XX06\n",
      "11    CC00617XX15\n",
      "Name: subject, dtype: object\n",
      "\n",
      "Bottom 12 subjects with lowest projection scores:\n",
      "293    CC00669XX18\n",
      "294    CC00852XX11\n",
      "295    CC00584XX16\n",
      "296    CC00080XX07\n",
      "297    CC01199XX21\n",
      "298    CC00139XX16\n",
      "299    CC00688XX21\n",
      "300    CC00223XX09\n",
      "301    CC00380XX10\n",
      "302    CC00861XX12\n",
      "303    CC00292XX13\n",
      "304    CC01194XX16\n",
      "Name: subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extract top and bottom 12 in upper case\n",
    "\n",
    "df_proj = pd.read_csv(\n",
    "    \"/neurospin/dico/rmenasria/Runs/03_main/Output/final_direction/dHCP/projection_STs_right_28_32.csv\"\n",
    ")\n",
    "top12 = df_proj.head(12).copy()[\"subject\"].str.upper()\n",
    "bottom12 = df_proj.tail(12).copy()[\"subject\"].str.upper()\n",
    "\n",
    "print(\"Top 12 subjects with highest projection scores:\")\n",
    "print(top12)\n",
    "print(\"\\nBottom 12 subjects with lowest projection scores:\")\n",
    "print(bottom12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regions_prematurity(\n",
    "    regions: List[str],\n",
    "    labels_path: str,\n",
    "    prem_class: List[str],\n",
    "    prem_target: str,\n",
    "    Cs=(0.01, 0.1, 1, 10),\n",
    "    n_perm: int = 200,\n",
    "    random_state: int = 42,\n",
    "    n_jobs: int = -1,\n",
    "    output_csv: Optional[str] = None,\n",
    "    output_coef_csv: Optional[str] = None,  \n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    coef_rows = []\n",
    "\n",
    "    for region in regions:\n",
    "        try:\n",
    "            data = prepare_dhcp_for_prematurity(\n",
    "                region=region,\n",
    "                labels_path=labels_path,\n",
    "                prem_class=prem_class,\n",
    "                prem_target=prem_target\n",
    "            )\n",
    "            res = classify_prematurity_with_perm(\n",
    "                data, Cs=Cs, n_permutations=n_perm,\n",
    "                random_state=random_state, n_jobs=n_jobs\n",
    "            )\n",
    "\n",
    "            # résumé perf\n",
    "            rows.append({\n",
    "                \"region\": region,\n",
    "                \"n\": int(len(data.y)),\n",
    "                \"best_C\": res[\"best_C\"],\n",
    "                \"AUC_mean\": res[\"AUC_mean\"],\n",
    "                \"AUC_std\": res[\"AUC_std\"],\n",
    "                \"perm_score\": res[\"perm_score\"],\n",
    "                \"perm_pval\": res[\"perm_pval\"],\n",
    "                \"perm_ci95\": res[\"perm_ci95\"]\n",
    "            })\n",
    "\n",
    "            # direction de classif (coefficients non-scalés)\n",
    "            coef_dict = res[\"coef_unscaled\"].copy()\n",
    "            coef_dict.pop(\"_sex_num\", None)  # on enlève la colonne sexe\n",
    "            # récupérer les coeffs dans l'ordre des embeddings\n",
    "            ordered_coeffs = [coef_dict[c] for c in data.embedding_cols if c != \"_sex_num\"]\n",
    "\n",
    "            coef_rows.append({\n",
    "                \"region\": region,\n",
    "                \"intercept\": res[\"intercept_unscaled\"],\n",
    "                \"coeffs\": ordered_coeffs  # une seule colonne avec la liste\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"[{region}] échec: {e}\")\n",
    "\n",
    "    # CSV 1: résumé perf\n",
    "    df = pd.DataFrame(rows)\n",
    "    if output_csv:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # CSV 2: directions\n",
    "    if coef_rows:\n",
    "        coef_df = pd.DataFrame(coef_rows)\n",
    "        if output_coef_csv:\n",
    "            # par défaut, pandas écrit la liste comme string JSON-like\n",
    "            coef_df.to_csv(output_coef_csv, index=False)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_list(base_path):\n",
    "    return sorted([\n",
    "        d for d in os.listdir(base_path)\n",
    "        if os.path.isdir(os.path.join(base_path, d))\n",
    "           and not d.startswith('all_models')\n",
    "           and not d.startswith('hcp')\n",
    "           and not d.startswith('ukb')\n",
    "           and not d.endswith('.csv')\n",
    "           and not d.endswith('.sh')\n",
    "           and not d.endswith('embeddings')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CINGULATE_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[CINGULATE_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FCLp-subsc-FCLa-INSULA_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FCLp-subsc-FCLa-INSULA_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FCMpost-SpC_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FCMpost-SpC_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FColl-SRh_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FColl-SRh_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FIP_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FIP_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FPO-SCu-ScCal_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[FPO-SCu-ScCal_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[LARGE_CINGULATE_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[LARGE_CINGULATE_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[Lobule_parietal_sup_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[Lobule_parietal_sup_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[OCCIPITAL_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[OCCIPITAL_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-SPeC_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-SPeC_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-SPoC_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-SPoC_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-sylv_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SC-sylv_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFinf-BROCA-SPeCinf_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFinf-BROCA-SPeCinf_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFint-FCMant_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFint-FCMant_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFint-SR_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFint-SR_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFinter-SFsup_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFinter-SFsup_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFmarginal-SFinfant_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFmarginal-SFinfant_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFmedian-SFpoltr-SFsup_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SFmedian-SFpoltr-SFsup_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SOr-SOlf_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SOr-SOlf_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SOr_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SOr_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SPeC_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SPeC_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SPoC_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SPoC_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STi-SOTlat_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STi-SOTlat_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STi-STs-STpol_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STi-STs-STpol_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STs_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STs_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STsbr_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[STsbr_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[ScCal-SLi_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[ScCal-SLi_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SsP-SPaint_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[SsP-SPaint_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[fronto-parietal_medial_face_left] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "[fronto-parietal_medial_face_right] filtre prem_class ['<28', '>=37']: 374 -> 296\n",
      "                               region    n  best_C  AUC_mean   AUC_std  \\\n",
      "0                      CINGULATE_left  290    1.00  0.677727  0.116884   \n",
      "1                     CINGULATE_right  290    1.00  0.828290  0.048135   \n",
      "2         FCLp-subsc-FCLa-INSULA_left  290    0.10  0.925747  0.088954   \n",
      "3        FCLp-subsc-FCLa-INSULA_right  290    0.10  0.945335  0.047610   \n",
      "4                    FCMpost-SpC_left  290    0.10  0.788485  0.180670   \n",
      "5                   FCMpost-SpC_right  290   10.00  0.774751  0.156921   \n",
      "6                      FColl-SRh_left  290   10.00  0.948398  0.041003   \n",
      "7                     FColl-SRh_right  290    1.00  0.868084  0.069871   \n",
      "8                            FIP_left  290    0.01  0.792165  0.138350   \n",
      "9                           FIP_right  290    1.00  0.801028  0.119638   \n",
      "10                 FPO-SCu-ScCal_left  290   10.00  0.761937  0.189472   \n",
      "11                FPO-SCu-ScCal_right  290   10.00  0.916634  0.086567   \n",
      "12               LARGE_CINGULATE_left  290    1.00  0.910498  0.070625   \n",
      "13              LARGE_CINGULATE_right  290   10.00  0.930346  0.053884   \n",
      "14           Lobule_parietal_sup_left  290    0.10  0.797143  0.102712   \n",
      "15          Lobule_parietal_sup_right  290   10.00  0.794708  0.158966   \n",
      "16                     OCCIPITAL_left  290    1.00  0.887597  0.083055   \n",
      "17                    OCCIPITAL_right  290   10.00  0.906861  0.061342   \n",
      "18                       SC-SPeC_left  290    1.00  0.732273  0.152263   \n",
      "19                      SC-SPeC_right  290   10.00  0.827846  0.107153   \n",
      "20                       SC-SPoC_left  290   10.00  0.776526  0.214533   \n",
      "21                      SC-SPoC_right  290   10.00  0.807284  0.165271   \n",
      "22                       SC-sylv_left  290   10.00  0.757089  0.098373   \n",
      "23                      SC-sylv_right  290   10.00  0.795866  0.150106   \n",
      "24           SFinf-BROCA-SPeCinf_left  290    0.10  0.719708  0.141231   \n",
      "25          SFinf-BROCA-SPeCinf_right  290   10.00  0.536894  0.170524   \n",
      "26                  SFint-FCMant_left  290   10.00  0.770996  0.092255   \n",
      "27                 SFint-FCMant_right  290   10.00  0.742879  0.143212   \n",
      "28                      SFint-SR_left  290   10.00  0.869102  0.046885   \n",
      "29                     SFint-SR_right  290   10.00  0.778474  0.092586   \n",
      "30                 SFinter-SFsup_left  290    1.00  0.749448  0.185273   \n",
      "31                SFinter-SFsup_right  290    1.00  0.721959  0.107335   \n",
      "32           SFmarginal-SFinfant_left  290    0.01  0.732067  0.188884   \n",
      "33          SFmarginal-SFinfant_right  290    1.00  0.728268  0.149866   \n",
      "34        SFmedian-SFpoltr-SFsup_left  290    1.00  0.754405  0.185180   \n",
      "35       SFmedian-SFpoltr-SFsup_right  290    0.10  0.755768  0.081344   \n",
      "36                      SOr-SOlf_left  290    1.00  0.766277  0.161655   \n",
      "37                     SOr-SOlf_right  290    0.01  0.492316  0.200003   \n",
      "38                           SOr_left  290    0.01  0.780108  0.144729   \n",
      "39                          SOr_right  290   10.00  0.668831  0.210925   \n",
      "40                          SPeC_left  290    1.00  0.776028  0.150017   \n",
      "41                         SPeC_right  290   10.00  0.717478  0.139974   \n",
      "42                          SPoC_left  290    0.01  0.756310  0.199127   \n",
      "43                         SPoC_right  290    0.01  0.785649  0.256629   \n",
      "44                    STi-SOTlat_left  290    1.00  0.949924  0.035753   \n",
      "45                   STi-SOTlat_right  290    0.10  0.975444  0.019654   \n",
      "46                 STi-STs-STpol_left  290    1.00  0.952792  0.067541   \n",
      "47                STi-STs-STpol_right  290    1.00  0.980032  0.029802   \n",
      "48                           STs_left  290    1.00  0.928745  0.089268   \n",
      "49                          STs_right  290   10.00  0.951396  0.042510   \n",
      "50                         STsbr_left  290    1.00  0.895519  0.051863   \n",
      "51                        STsbr_right  290   10.00  0.760595  0.136233   \n",
      "52                     ScCal-SLi_left  290    1.00  0.860422  0.118284   \n",
      "53                    ScCal-SLi_right  290   10.00  0.902727  0.046000   \n",
      "54                    SsP-SPaint_left  290    0.01  0.823690  0.055603   \n",
      "55                   SsP-SPaint_right  290    1.00  0.888431  0.083178   \n",
      "56   fronto-parietal_medial_face_left  290    1.00  0.882814  0.126473   \n",
      "57  fronto-parietal_medial_face_right  290   10.00  0.953626  0.040136   \n",
      "\n",
      "    perm_score  perm_pval  perm_ci95  \n",
      "0     0.677727   0.062227   0.688139  \n",
      "1     0.828290   0.000803   0.685628  \n",
      "2     0.925747   0.000089   0.679149  \n",
      "3     0.945335   0.000089   0.685077  \n",
      "4     0.788485   0.003393   0.682364  \n",
      "5     0.774751   0.005803   0.685779  \n",
      "6     0.948398   0.000089   0.688220  \n",
      "7     0.868084   0.000268   0.683747  \n",
      "8     0.792165   0.001518   0.685077  \n",
      "9     0.801028   0.002410   0.685834  \n",
      "10    0.761937   0.008928   0.687008  \n",
      "11    0.916634   0.000089   0.684411  \n",
      "12    0.910498   0.000089   0.686483  \n",
      "13    0.930346   0.000089   0.684942  \n",
      "14    0.797143   0.001696   0.686104  \n",
      "15    0.794708   0.004017   0.686996  \n",
      "16    0.887597   0.000179   0.684129  \n",
      "17    0.906861   0.000089   0.688332  \n",
      "18    0.732273   0.016338   0.686165  \n",
      "19    0.827846   0.000714   0.687522  \n",
      "20    0.776526   0.005803   0.689504  \n",
      "21    0.807284   0.001428   0.683692  \n",
      "22    0.757089   0.010803   0.688386  \n",
      "23    0.795866   0.003214   0.684189  \n",
      "24    0.719708   0.021605   0.686687  \n",
      "25    0.536894   0.381305   0.687195  \n",
      "26    0.770996   0.006785   0.685152  \n",
      "27    0.742879   0.012410   0.680921  \n",
      "28    0.869102   0.000268   0.687254  \n",
      "29    0.778474   0.004196   0.681821  \n",
      "30    0.749448   0.012142   0.686550  \n",
      "31    0.721959   0.024194   0.687834  \n",
      "32    0.732067   0.017141   0.686483  \n",
      "33    0.728268   0.019195   0.685653  \n",
      "34    0.754405   0.012588   0.691444  \n",
      "35    0.755768   0.010267   0.687325  \n",
      "36    0.766277   0.007053   0.688077  \n",
      "37    0.492316   0.537095   0.681873  \n",
      "38    0.780108   0.003125   0.681635  \n",
      "39    0.668831   0.068030   0.687705  \n",
      "40    0.776028   0.006071   0.687436  \n",
      "41    0.717478   0.025266   0.685929  \n",
      "42    0.756310   0.006874   0.685878  \n",
      "43    0.785649   0.002321   0.683166  \n",
      "44    0.949924   0.000089   0.687247  \n",
      "45    0.975444   0.000089   0.687514  \n",
      "46    0.952792   0.000089   0.683150  \n",
      "47    0.980032   0.000089   0.681753  \n",
      "48    0.928745   0.000089   0.682317  \n",
      "49    0.951396   0.000089   0.684949  \n",
      "50    0.895519   0.000089   0.687630  \n",
      "51    0.760595   0.008571   0.683085  \n",
      "52    0.860422   0.000268   0.683548  \n",
      "53    0.902727   0.000089   0.679332  \n",
      "54    0.823690   0.000446   0.685476  \n",
      "55    0.888431   0.000089   0.684048  \n",
      "56    0.882814   0.000089   0.681624  \n",
      "57    0.953626   0.000089   0.684556  \n"
     ]
    }
   ],
   "source": [
    "regions_test= [\n",
    "    \"SFinf-BROCA-SPeCinf_right\",\n",
    "    \"SFinf-BROCA-SPeCinf_left\",\n",
    "    \"ScCal-SLi_left\"\n",
    "]\n",
    "\n",
    "regions = get_region_list(base_path)\n",
    "\n",
    "prem_filter = [\"<28\", \">=37\"]   # on garde uniquement ces classes\n",
    "prem_target = \"<28\"             # la classe positive = prématurés\n",
    "\n",
    "out = run_regions_prematurity(\n",
    "    regions=regions,\n",
    "    labels_path=labels_path,        \n",
    "    prem_class=prem_filter,\n",
    "    prem_target=prem_target,\n",
    "    Cs=[0.01, 0.1, 1, 10],\n",
    "    n_perm=11200,                     \n",
    "    n_jobs=-1,\n",
    "    output_csv=\"/neurospin/dico/rmenasria/Runs/03_main/Output/final/classif_prematurity_dHCP_final_28.csv\",\n",
    "    output_coef_csv=\"/neurospin/dico/rmenasria/Runs/03_main/Output/final/classif_prematurity_dHCP_directions_final_28.csv\"\n",
    ")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier généré : prematurity_AUC_by_region_1205.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/neurospin/dico/rmenasria/Runs/01_essai/Program/2023_jlaval_STSbabies/contrastive/notebooks/racim/prematurity_classification_stats_1205.csv')\n",
    "\n",
    "# Pivot pour avoir une colonne AUC par tranche\n",
    "df_pivot = df.pivot(index='region', columns='tranche', values='AUC_mean')\n",
    "\n",
    "# Renommer les colonnes pour clarifier\n",
    "df_pivot = df_pivot.rename(columns={\n",
    "    '<27': 'AUC_27',\n",
    "    '27-32': 'AUC_27_32',\n",
    "    '32-37': 'AUC_32_37'\n",
    "}).reset_index()\n",
    "\n",
    "# Sauvegarder le nouveau CSV\n",
    "output_csv = 'prematurity_AUC_by_region_1205.csv'\n",
    "df_pivot.to_csv(output_csv, index=False)\n",
    "print(f\"Fichier généré : {output_csv}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"/neurospin/dico/rmenasria/Runs/03_main/Output/final/classif_prematurity_dHCP_final_28_32.csv\")\n",
    "\n",
    "# add a column thresholded_auc = AUC_mean if perm_pval < 0.05/56 else 0\n",
    "df_results['thresholded_auc'] = df_results.apply(\n",
    "    lambda row: row['AUC_mean'] if row['perm_pval'] < 0.05 / 56 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Select the columns \"region\" and \"thresholded_auc\" and save to CSV\n",
    "df_results[[\"region\", \"thresholded_auc\"]].to_csv(\n",
    "    \"/neurospin/dico/rmenasria/Runs/03_main/Output/final/whole_brain_visu/prematurity_thresholded_auc_28_32.csv\", \n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_ABCD = pd.read_csv(\"/neurospin/dico/rmenasria/Runs/03_main/Output/final/prematurity/report_final/ABCD_prematurity_results_final_28_32_corrected.csv\")\n",
    "\n",
    "# only select columns region, AUC_mean, AUC_std, perm_pval\n",
    "df_results_ABCD = df_results_ABCD[[\"region\", \"auc_mean\", \"auc_std\", \"perm_pvalue\"]]\n",
    "df_results_ABCD.to_csv(\n",
    "    \"/neurospin/dico/rmenasria/Runs/03_main/Output/final/prematurity/report_final/table_supplementary_ABCD_28_32.csv\", \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier généré : prematurity_AUC_by_region_thresholded_0708_dHCP.csv\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier CSV d'origine\n",
    "df = pd.read_csv('/neurospin/dico/rmenasria/Runs/03_main/Program/2025_rmenasria_prematurity/notebooks/racim/prematurity_classification_dHCP_0708.csv')\n",
    "\n",
    "# Remplacer les AUC_mean non significatifs (p_value >= 0.05) par 0\n",
    "df.loc[df['p_value'] >= 0.05, 'AUC_mean'] = 0.0\n",
    "\n",
    "# Pivot pour avoir une colonne AUC par tranche\n",
    "df_pivot = df.pivot(index='region', columns='tranche', values='AUC_mean')\n",
    "\n",
    "# Renommer les colonnes\n",
    "df_pivot = df_pivot.rename(columns={\n",
    "    '<28': 'AUC_28',\n",
    "    '28-32': 'AUC_28_32',\n",
    "    '32-37': 'AUC_37'\n",
    "}).reset_index()\n",
    "\n",
    "# Exporter le résultat\n",
    "output_csv = 'prematurity_AUC_by_region_thresholded_0708_dHCP.csv'\n",
    "df_pivot.to_csv(output_csv, index=False)\n",
    "print(f\"Fichier généré : {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
